{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 임베딩 로드\n",
    "- `word2vec`: Word2Vec\n",
    "- `nnse`: Non-negative Sparse Embedding (NNSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = pd.read_parquet('./data/embeddings/word2vec_300.parquet')\n",
    "nnse = pd.read_parquet('./data/embeddings/nnse_2500.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>d4</th>\n",
       "      <th>d5</th>\n",
       "      <th>d6</th>\n",
       "      <th>d7</th>\n",
       "      <th>d8</th>\n",
       "      <th>d9</th>\n",
       "      <th>d10</th>\n",
       "      <th>...</th>\n",
       "      <th>d291</th>\n",
       "      <th>d292</th>\n",
       "      <th>d293</th>\n",
       "      <th>d294</th>\n",
       "      <th>d295</th>\n",
       "      <th>d296</th>\n",
       "      <th>d297</th>\n",
       "      <th>d298</th>\n",
       "      <th>d299</th>\n",
       "      <th>d300</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.086914</td>\n",
       "      <td>0.087891</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.069336</td>\n",
       "      <td>-0.108887</td>\n",
       "      <td>-0.081543</td>\n",
       "      <td>-0.154297</td>\n",
       "      <td>0.020752</td>\n",
       "      <td>0.131836</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.168945</td>\n",
       "      <td>-0.088867</td>\n",
       "      <td>-0.080566</td>\n",
       "      <td>0.064941</td>\n",
       "      <td>0.061279</td>\n",
       "      <td>-0.047363</td>\n",
       "      <td>-0.058838</td>\n",
       "      <td>-0.047607</td>\n",
       "      <td>0.014465</td>\n",
       "      <td>-0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>-0.011780</td>\n",
       "      <td>-0.047363</td>\n",
       "      <td>0.044678</td>\n",
       "      <td>0.063477</td>\n",
       "      <td>-0.018188</td>\n",
       "      <td>-0.063965</td>\n",
       "      <td>-0.001312</td>\n",
       "      <td>-0.072266</td>\n",
       "      <td>0.064453</td>\n",
       "      <td>0.086426</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022583</td>\n",
       "      <td>0.003723</td>\n",
       "      <td>-0.082520</td>\n",
       "      <td>0.081543</td>\n",
       "      <td>0.007935</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.018433</td>\n",
       "      <td>0.071289</td>\n",
       "      <td>-0.034912</td>\n",
       "      <td>0.024170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>-0.015747</td>\n",
       "      <td>-0.028320</td>\n",
       "      <td>0.083496</td>\n",
       "      <td>0.050293</td>\n",
       "      <td>-0.110352</td>\n",
       "      <td>0.031738</td>\n",
       "      <td>-0.014221</td>\n",
       "      <td>-0.089844</td>\n",
       "      <td>0.117676</td>\n",
       "      <td>0.118164</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011292</td>\n",
       "      <td>-0.015625</td>\n",
       "      <td>-0.033447</td>\n",
       "      <td>-0.020630</td>\n",
       "      <td>-0.019409</td>\n",
       "      <td>0.063965</td>\n",
       "      <td>0.020142</td>\n",
       "      <td>0.006866</td>\n",
       "      <td>0.061035</td>\n",
       "      <td>-0.148438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>0.007050</td>\n",
       "      <td>-0.073242</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.022583</td>\n",
       "      <td>-0.132812</td>\n",
       "      <td>0.198242</td>\n",
       "      <td>0.112793</td>\n",
       "      <td>-0.107910</td>\n",
       "      <td>0.071777</td>\n",
       "      <td>0.020874</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.233398</td>\n",
       "      <td>-0.036377</td>\n",
       "      <td>-0.093750</td>\n",
       "      <td>0.182617</td>\n",
       "      <td>0.027100</td>\n",
       "      <td>0.127930</td>\n",
       "      <td>-0.024780</td>\n",
       "      <td>0.011230</td>\n",
       "      <td>0.164062</td>\n",
       "      <td>0.106934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>0.026733</td>\n",
       "      <td>-0.090820</td>\n",
       "      <td>0.027832</td>\n",
       "      <td>0.204102</td>\n",
       "      <td>0.006226</td>\n",
       "      <td>-0.090332</td>\n",
       "      <td>0.022583</td>\n",
       "      <td>-0.161133</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>0.061035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026855</td>\n",
       "      <td>-0.027954</td>\n",
       "      <td>0.030884</td>\n",
       "      <td>0.040527</td>\n",
       "      <td>-0.130859</td>\n",
       "      <td>0.083008</td>\n",
       "      <td>0.015747</td>\n",
       "      <td>-0.116699</td>\n",
       "      <td>-0.029419</td>\n",
       "      <td>-0.070801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            d1        d2        d3        d4        d5        d6        d7  \\\n",
       "word                                                                         \n",
       "in    0.070312  0.086914  0.087891  0.062500  0.069336 -0.108887 -0.081543   \n",
       "for  -0.011780 -0.047363  0.044678  0.063477 -0.018188 -0.063965 -0.001312   \n",
       "that -0.015747 -0.028320  0.083496  0.050293 -0.110352  0.031738 -0.014221   \n",
       "is    0.007050 -0.073242  0.171875  0.022583 -0.132812  0.198242  0.112793   \n",
       "on    0.026733 -0.090820  0.027832  0.204102  0.006226 -0.090332  0.022583   \n",
       "\n",
       "            d8        d9       d10    ...         d291      d292      d293  \\\n",
       "word                                  ...                                    \n",
       "in   -0.154297  0.020752  0.131836    ...    -0.168945 -0.088867 -0.080566   \n",
       "for  -0.072266  0.064453  0.086426    ...    -0.022583  0.003723 -0.082520   \n",
       "that -0.089844  0.117676  0.118164    ...    -0.011292 -0.015625 -0.033447   \n",
       "is   -0.107910  0.071777  0.020874    ...    -0.233398 -0.036377 -0.093750   \n",
       "on   -0.161133  0.132812  0.061035    ...     0.026855 -0.027954  0.030884   \n",
       "\n",
       "          d294      d295      d296      d297      d298      d299      d300  \n",
       "word                                                                        \n",
       "in    0.064941  0.061279 -0.047363 -0.058838 -0.047607  0.014465 -0.062500  \n",
       "for   0.081543  0.007935  0.000477  0.018433  0.071289 -0.034912  0.024170  \n",
       "that -0.020630 -0.019409  0.063965  0.020142  0.006866  0.061035 -0.148438  \n",
       "is    0.182617  0.027100  0.127930 -0.024780  0.011230  0.164062  0.106934  \n",
       "on    0.040527 -0.130859  0.083008  0.015747 -0.116699 -0.029419 -0.070801  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>d4</th>\n",
       "      <th>d5</th>\n",
       "      <th>d6</th>\n",
       "      <th>d7</th>\n",
       "      <th>d8</th>\n",
       "      <th>d9</th>\n",
       "      <th>d10</th>\n",
       "      <th>...</th>\n",
       "      <th>d2491</th>\n",
       "      <th>d2492</th>\n",
       "      <th>d2493</th>\n",
       "      <th>d2494</th>\n",
       "      <th>d2495</th>\n",
       "      <th>d2496</th>\n",
       "      <th>d2497</th>\n",
       "      <th>d2498</th>\n",
       "      <th>d2499</th>\n",
       "      <th>d2500</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>expletive</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>measles</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proven</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perverted</th>\n",
       "      <td>0.004916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inconsequential</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       d1   d2   d3   d4   d5        d6   d7   d8   d9  d10  \\\n",
       "word                                                                          \n",
       "expletive        0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
       "measles          0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
       "proven           0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
       "perverted        0.004916  0.0  0.0  0.0  0.0  0.006557  0.0  0.0  0.0  0.0   \n",
       "inconsequential  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                 ...    d2491  d2492  d2493  d2494  d2495     d2496  d2497  \\\n",
       "word             ...                                                         \n",
       "expletive        ...      0.0    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
       "measles          ...      0.0    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
       "proven           ...      0.0    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
       "perverted        ...      0.0    0.0    0.0    0.0    0.0  0.005495    0.0   \n",
       "inconsequential  ...      0.0    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
       "\n",
       "                 d2498  d2499  d2500  \n",
       "word                                  \n",
       "expletive          0.0    0.0    0.0  \n",
       "measles            0.0    0.0    0.0  \n",
       "proven             0.0    0.0    0.0  \n",
       "perverted          0.0    0.0    0.0  \n",
       "inconsequential    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 2500 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnse.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 응집도 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 차원 별 대표 단어 확인 (정성적)\n",
    "* **차원의 대표 단어**: 해당 차원의 값이 큰 단어 순으로 정렬했을 때 top K개의 단어\n",
    "* 임베딩 차원 갯수\n",
    "  * `word2vec`: 300차원\n",
    "  * `nnse`: 2,500 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_embeddings_for_words(words, embeddings):\n",
    "    \"\"\"주어진 단어들의 임베딩을 `pandas.DataFrame` 형태로 반환\n",
    "    \n",
    "    Args:\n",
    "        words (list): 단어 리스트\n",
    "        embeddings (pandas.DataFrame): 임베딩 행렬\n",
    "    Returns:\n",
    "        pandas.DataFrame: 주어진 단어들의 임베딩\n",
    "        \n",
    "        단어가 임베딩 행렬에 없는 경우 제외\n",
    "    \"\"\"\n",
    "    return embeddings.loc[embeddings.index.intersection(words)].copy()\n",
    "\n",
    "def _explain_dim(dim, embeddings, k):\n",
    "    \"\"\"단일 차원의 대표 단어 반환\n",
    "    \n",
    "    주어진 `embeddings` DataFrame을 입력된 차원값이 큰 순으로 정렬한 후, top k 단어 반환하는 방식\n",
    "    \n",
    "    Args:\n",
    "        index (int): 차원 번호. 0부터 시작 (nnse의 경우 0~2499)\n",
    "        embeddings (pandas.DataFrame): 전체 단어 임베딩\n",
    "    Returns:\n",
    "        tuple: (차원, 대표 단어)\n",
    "    \"\"\"\n",
    "    desc = embeddings.sort_values(by=dim, ascending=False).index.tolist()[:k]\n",
    "    return (dim, desc)\n",
    "\n",
    "def explain_dims(dims, embeddings, k=5):\n",
    "    \"\"\"여러 차원의 대표 단어 반환\n",
    "    \n",
    "    주어진 `embeddings` DataFrame을 입력된 차원값이 큰 순으로 정렬한 후, top k 단어 반환하는 방식\n",
    "    `_explain_dim` 활용\n",
    "    \n",
    "    Args:\n",
    "        indices (list[int]): 차원 번호 리스트. 차원 번호는 0부터 시작 (nnse의 경우 0~2499)\n",
    "        embeddings (pandas.DataFrame): 전체 단어 임베딩\n",
    "    Returns:\n",
    "        tuple: (차원, 대표 단어)\n",
    "    \"\"\"\n",
    "    results = [_explain_dim(dim, embeddings, k) for dim in dims]\n",
    "    pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec\n",
    "각 차원별로 일관된 개념이 드러나지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('d4', ['declarer', 'repose', 'toppings', 'dictators', 'communism']),\n",
      " ('d6', ['mage', 'unclean', 'drinker', 'alcoholic', 'alibi'])]\n"
     ]
    }
   ],
   "source": [
    "dims_to_inspect = ['d4', 'd6']\n",
    "explain_dims(dims_to_inspect, word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NNSE\n",
    "각 차원별로 일관된 개념이 드러남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('d1703', ['pharmacists', 'nurses', 'physicians', 'practitioners', 'doctors']),\n",
      " ('d1255',\n",
      "  ['examine', 'investigate', 'investigating', 'exploring', 'examining'])]\n"
     ]
    }
   ],
   "source": [
    "dims_to_inspect = ['d1703', 'd1255']\n",
    "explain_dims(dims_to_inspect, nnse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 차원 별 클러스터 응집도 확인 (정량적)\n",
    "- 대표 단어 목록(클러스터)이 주어지면, 모든 단어 pair끼리의 `cosine` 값을 계산한 후 평균을 냄 (클러스터 질 평가)\n",
    "- 평균 응집도 결과 (아래에서 계산)\n",
    "  - word2vec: 0.1544\n",
    "  - NNSE: 0.6443"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def caculate_similarity(w1, w2, embedding):\n",
    "    w1_embed, w2_embed = embedding.loc[w1], embedding.loc[w2]\n",
    "    return 1 - cosine(w1_embed, w2_embed)\n",
    "\n",
    "def calculate_cohesion(words, embedding):\n",
    "    if len(words) <= 1: # 단어 클러스터에 속한 단어가 1개 이하\n",
    "        return 0.0\n",
    "    pairs = combinations(words, 2)\n",
    "    sim_scores = []\n",
    "    for pair in pairs:\n",
    "        w1, w2 = pair[0], pair[1]\n",
    "        sim_score = caculate_similarity(w1, w2, embedding)\n",
    "        sim_scores.append(sim_score)\n",
    "    return sum(sim_scores) / len(sim_scores)\n",
    "\n",
    "def get_avg_score(scores):\n",
    "    return sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('d1', 'd300')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims = ['d{}'.format(d) for d in range(1, 301)]\n",
    "dims[0], dims[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embeddings = word2vec\n",
    "scores = []\n",
    "for d in dims:\n",
    "    d, cluster = _explain_dim(d, embeddings, k=5)\n",
    "    score = calculate_cohesion(cluster, embeddings)\n",
    "    scores.append((d, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 응집도: 0.1544\n"
     ]
    }
   ],
   "source": [
    "avg_score = get_avg_score([s[1] for s in word2vec_scores])\n",
    "print('평균 응집도: {:.4f}'.format(avg_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NNSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('d1', 'd2500')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims = ['d{}'.format(d) for d in range(1, 2501)]\n",
    "dims[0], dims[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = nnse\n",
    "scores = []\n",
    "for d in dims:\n",
    "    d, cluster = _explain_dim(d, embeddings, k=5)\n",
    "    score = calculate_cohesion(cluster, embeddings)\n",
    "    scores.append((d, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 응집도: 0.6443\n"
     ]
    }
   ],
   "source": [
    "avg_score = get_avg_score([s[1] for s in scores])\n",
    "print('평균 응집도: {:.4f}'.format(avg_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
