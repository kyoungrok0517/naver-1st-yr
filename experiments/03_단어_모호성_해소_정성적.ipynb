{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "import functools\n",
    "from pprint import pprint\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `load_word2vec`, `load_nnse`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word2vec():\n",
    "    \"\"\"word2vec 임베딩 행렬을 `pandas.DataFrame` 형태로 로드\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: Index: 단어, Column: 차원 값 형태\n",
    "    \"\"\"\n",
    "    embeddings = pd.read_parquet('./data/embeddings/word2vec_300.parquet')\n",
    "    return embeddings\n",
    "\n",
    "def load_nnse():\n",
    "    \"\"\"NNSE 임베딩 행렬을 `pandas.DataFrame` 형태로 로드\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: Index: 단어, Column: 차원 값 형태\n",
    "    \"\"\"\n",
    "    embeddings = pd.read_parquet('./data/embeddings/nnse_2500.parquet')\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>d4</th>\n",
       "      <th>d5</th>\n",
       "      <th>d6</th>\n",
       "      <th>d7</th>\n",
       "      <th>d8</th>\n",
       "      <th>d9</th>\n",
       "      <th>d10</th>\n",
       "      <th>...</th>\n",
       "      <th>d2491</th>\n",
       "      <th>d2492</th>\n",
       "      <th>d2493</th>\n",
       "      <th>d2494</th>\n",
       "      <th>d2495</th>\n",
       "      <th>d2496</th>\n",
       "      <th>d2497</th>\n",
       "      <th>d2498</th>\n",
       "      <th>d2499</th>\n",
       "      <th>d2500</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>expletive</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>measles</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proven</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perverted</th>\n",
       "      <td>0.004916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inconsequential</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       d1   d2   d3   d4   d5        d6   d7   d8   d9  d10  \\\n",
       "word                                                                          \n",
       "expletive        0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
       "measles          0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
       "proven           0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
       "perverted        0.004916  0.0  0.0  0.0  0.0  0.006557  0.0  0.0  0.0  0.0   \n",
       "inconsequential  0.000000  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                 ...    d2491  d2492  d2493  d2494  d2495     d2496  d2497  \\\n",
       "word             ...                                                         \n",
       "expletive        ...      0.0    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
       "measles          ...      0.0    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
       "proven           ...      0.0    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
       "perverted        ...      0.0    0.0    0.0    0.0    0.0  0.005495    0.0   \n",
       "inconsequential  ...      0.0    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
       "\n",
       "                 d2498  d2499  d2500  \n",
       "word                                  \n",
       "expletive          0.0    0.0    0.0  \n",
       "measles            0.0    0.0    0.0  \n",
       "proven             0.0    0.0    0.0  \n",
       "perverted          0.0    0.0    0.0  \n",
       "inconsequential    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 2500 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_nnse = load_nnse()\n",
    "emb_nnse.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `get_embeddings_for_words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_for_words(words, embeddings):\n",
    "    \"\"\"주어진 단어들의 임베딩을 `pandas.DataFrame` 형태로 반환\n",
    "    \n",
    "    Args:\n",
    "        words (list): 단어 리스트\n",
    "        embeddings (pandas.DataFrame): 임베딩 행렬 (`load_word2vec`, `load_nnse` 반환 형태)\n",
    "    Returns:\n",
    "        pandas.DataFrame: 주어진 단어들의 임베딩\n",
    "        \n",
    "        단어가 임베딩 행렬에 없는 경우 제외\n",
    "    \"\"\"\n",
    "    return embeddings.loc[embeddings.index.intersection(words)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>d4</th>\n",
       "      <th>d5</th>\n",
       "      <th>d6</th>\n",
       "      <th>d7</th>\n",
       "      <th>d8</th>\n",
       "      <th>d9</th>\n",
       "      <th>d10</th>\n",
       "      <th>...</th>\n",
       "      <th>d2491</th>\n",
       "      <th>d2492</th>\n",
       "      <th>d2493</th>\n",
       "      <th>d2494</th>\n",
       "      <th>d2495</th>\n",
       "      <th>d2496</th>\n",
       "      <th>d2497</th>\n",
       "      <th>d2498</th>\n",
       "      <th>d2499</th>\n",
       "      <th>d2500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>including</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>standards</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>differs</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 2500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            d1   d2   d3   d4   d5   d6   d7   d8   d9  d10  ...    d2491  \\\n",
       "including  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "standards  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "differs    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "\n",
       "           d2492  d2493  d2494  d2495  d2496  d2497  d2498  d2499  d2500  \n",
       "including    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "standards    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "differs      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[3 rows x 2500 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['standards', 'differs', 'including', 'abcc'] # 'abcc'는 행렬에 없음\n",
    "word_embeddings = get_embeddings_for_words(words, emb_nnse)\n",
    "word_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `compose_embeddings_sum` (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_embeddings_sum(target_embs, context_embs):\n",
    "    \"\"\"[Baseline] 주어진 단어 임베딩들의 합을 `pandas.DataFrame` 형태로 반환.\n",
    "    \n",
    "    단순 덧셈\n",
    "    \n",
    "    Args:\n",
    "        target_embs (pandas.DataFrame): 합성할 단어 임베딩. `get_embeddings_for_words`의 반환값\n",
    "        context_embs (pandas.DataFrame): 합성할 단어 임베딩. `get_embeddings_for_words`의 반환값\n",
    "    Returns:\n",
    "        pandas.DataFrame: 합성된 단어 임베딩 (덧셈). shape은 (1, #_of_dimensions)\n",
    "    \"\"\"\n",
    "    # 임베딩 행렬 복제본에 작업\n",
    "    target_embs = target_embs.copy()\n",
    "    context_embs = context_embs.copy()\n",
    "    \n",
    "    embs = pd.concat([target_embs, context_embs])\n",
    "    return embs.sum(axis=0).values.reshape(1, -1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2500)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 합성 결과물 shape = (1, #_of_dimensions)\n",
    "compose_embeddings_sum(word_embeddings.iloc[1:], word_embeddings).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `compose_embeddings_reactive` (My)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(inputs):\n",
    "    \"\"\"\n",
    "    Calculate the softmax for the give inputs (array)\n",
    "    :param inputs:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return np.exp(inputs) / float(sum(np.exp(inputs)))\n",
    "\n",
    "DEBUG = False\n",
    "def compose_embeddings_reactive(target_embs, context_embs):\n",
    "    \"\"\"[Proposing] 주어진 단어 임베딩들의 contextualized 합을 `pandas.DataFrame` 형태로 반환.\n",
    "    \n",
    "    1. \n",
    "    2. \n",
    "    3. \n",
    "    \n",
    "    Args:\n",
    "        target_embs (pandas.DataFrame): 합성할 단어 임베딩. `get_embeddings_for_words`의 반환값\n",
    "        context_embs (pandas.DataFrame): 합성할 단어 임베딩. `get_embeddings_for_words`의 반환값\n",
    "    Returns:\n",
    "        pandas.DataFrame: 합성된 단어 임베딩 (Contextualized). shape은 (1, #_of_dimensions)\n",
    "    \"\"\"\n",
    "    if type(target_embs) != pd.core.frame.DataFrame and type(context_embs) != pd.core.frame.DataFrame:\n",
    "        raise ValueError('target_embs and context_embs must be DataFrame')\n",
    "    \n",
    "    # 임베딩 행렬 복제본에 작업 (원본 행렬 유지)\n",
    "    target_embs = target_embs.copy()\n",
    "    context_embs = context_embs.copy()\n",
    "    \n",
    "    # 임베딩을 1차원 벡터로 변환 (context는 먼저 합친 후 변환)\n",
    "    target = target_embs.sum().values\n",
    "    context = context_embs.sum().values\n",
    "    \n",
    "    # target*context\n",
    "    target = np.multiply(target, context)\n",
    "    \n",
    "    # deactivate weak dimensions\n",
    "#     thres = 0.001\n",
    "#     weak_dims = target < thres\n",
    "#     target[weak_dims] = 0.0\n",
    "\n",
    "    # 반환값\n",
    "    result = normalize(target.reshape(1, -1))\n",
    "#     result = target.reshape(1, -1)\n",
    "\n",
    "    # 디버깅\n",
    "    if DEBUG:\n",
    "        print('[Words]', ', '.join(target_embs.index.tolist() + context_embs.index.tolist()))\n",
    "        explain = explain_dims(result.nonzero()[1], result.flatten(), emb_nnse)\n",
    "        pprint(explain)\n",
    "\n",
    "#     return target.reshape(1, -1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `explain_dim`, `explain_dims`, `get_sig_dims`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_cache = {}\n",
    "def _explain_dim(index, emb, embeddings):\n",
    "    k = 5\n",
    "    col = 'd{}'.format(index+1)\n",
    "    if not col in desc_cache:\n",
    "        desc_cache[col] = embeddings.sort_values(by=col, ascending=False).index.tolist()[:k]\n",
    "    desc =  desc_cache[col]\n",
    "    return (col, ', '.join(desc), emb[index])\n",
    "\n",
    "def explain_dims(indices, emb, embeddings, k=5):\n",
    "    results = [_explain_dim(i, emb, embeddings) for i in indices]\n",
    "    results = sorted(results, key=lambda item: item[2], reverse=True)\n",
    "    results = [(item[0], item[1], '{:.5f}'.format(item[2])) for item in results]\n",
    "    return results\n",
    "\n",
    "def get_sig_dims(emb, thres=0.01):\n",
    "    \"\"\"값이 `thres` 이상인 차원 index 반환\n",
    "    \n",
    "    Args:\n",
    "        emb (numpy.array): 차원을 추출할 임베딩. 1d array.\n",
    "    Returns:\n",
    "        numpy.array: sig 차원이 표시된 mask (예: array([False, True, False, ...]))\n",
    "    \"\"\"\n",
    "    if len(emb.shape) > 1:\n",
    "        raise ValueError('`emb` argument should be 1D array')\n",
    "    if type(thres) != float:\n",
    "        raise ValueError('`float` argument should be float')\n",
    "    \n",
    "    return np.where((emb > thres) == True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('d46', 'mac, macs, imac, macintosh, itunes', '0.74074'),\n",
       " ('d868', 'peach, pear, raspberry, plum, mango', '0.34687'),\n",
       " ('d111', 'crave, atlas, biz, chow, notebooks', '0.22558'),\n",
       " ('d2104', 'alcatel, lg, motorola, samsung, sony', '0.11278'),\n",
       " ('d1351', 'hewlett, packard, xerox, hp, compaq', '0.09343')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = get_embeddings_for_words(['apple'], emb_nnse).values.flatten()\n",
    "dims = get_sig_dims(emb)\n",
    "explain_dims(dims, emb, emb_nnse)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main\n",
    "주어진 다의어(예: apple)가 각기 다른 의미(sense)를 암시하는 문맥에 따라 의미가 변화하는 알고리즘을 **해석 가능한 형태**로 보여줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = get_embeddings_for_words(['apple'], emb_nnse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('d2104', 'alcatel, lg, motorola, samsung, sony', '0.11278'),\n",
       " ('d1724', 'aac, ogg, rm, ripper, converter', '0.06844'),\n",
       " ('d872', 'bea, microsoft, enterprise, ria, oracle', '0.05528'),\n",
       " ('d1778', 'cool, crazy, gadget, animation, sexy', '0.01466'),\n",
       " ('d1478', 'amoeba, rampage, shootout, buster, swat', '0.00589')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = get_embeddings_for_words(['electronics', 'latest', 'fast'], emb_nnse)\n",
    "\n",
    "res = compose_embeddings_reactive(target, context)\n",
    "dims = res.nonzero()[1]\n",
    "explain_dims(dims, target.values.flatten(), emb_nnse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('d868', 'peach, pear, raspberry, plum, mango', '0.34687'),\n",
       " ('d2203', 'godiva, starbucks, chocolate, candy, nestle', '0.05765'),\n",
       " ('d2095', 'oreo, crumb, kreme, krispy, shortbread', '0.03297'),\n",
       " ('d2239', 'rabe, raab, cheese, recipe, sauce', '0.02305')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = get_embeddings_for_words(['eat', 'ate', 'delicious'], emb_nnse)\n",
    "\n",
    "res = compose_embeddings_reactive(target, context)\n",
    "dims = res.nonzero()[1]\n",
    "explain_dims(dims, target.values.flatten(), emb_nnse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
